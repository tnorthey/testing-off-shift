{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6805d9ab-607c-4177-ad7d-f06ededd1ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cds/data/drpsrcf/cxi/cxilx9320/scratch/hdf5/smalldata/cxilx9320_Run0051.h5, FILE EXISTS, CONTINUE...\n",
      "azav shape: \n",
      "(36922, 35)\n",
      "/cds/data/drpsrcf/cxi/cxilx9320/scratch/hdf5/smalldata/cxilx9320_Run0052.h5, FILE EXISTS, CONTINUE...\n",
      "azav shape: \n",
      "(51767, 35)\n",
      "/cds/data/drpsrcf/cxi/cxilx9320/scratch/hdf5/smalldata/cxilx9320_Run0052.h5, FILE EXISTS, CONTINUE...\n",
      "azav shape: \n",
      "(51767, 35)\n",
      "azav_blank:\n",
      "[ 0.         45.88414824 45.61767424 46.1250131  41.51331354 37.47697747\n",
      " 33.59247584 29.54214625 25.70765775 22.19292579 19.2813566  16.55105008\n",
      " 14.91663906 13.61967635 11.74152437 10.46183459  9.71072751  8.9479021\n",
      "  8.54934325  8.14005307  7.87578099  7.87281265  7.53296748  7.33053469\n",
      "  7.11788128  7.7303047   7.16849776  6.89561744  6.87142522  6.74673971\n",
      "  6.89301082  6.75962607  6.76284605  6.67290836  6.33082746]\n",
      "irf:\n",
      "[1.11994208 1.03325187 1.0360032  1.03424948 1.03343949 1.03075833\n",
      " 1.02415787 1.01817664 1.02188446 1.02738992 1.0208765  1.0144064\n",
      " 1.0063406  0.99919899 0.98854491 0.98663622 0.98032883 0.97376432\n",
      " 0.96985319 0.96245809 0.95231973 0.95325469 0.94772119 0.93512907\n",
      " 0.92013556 0.91331393 0.90912456 0.90539904 0.88694514 0.86982319\n",
      " 0.8711514  0.86707208 0.84276328]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (35,) (33,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_127834/2782190453.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0mindexstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0mirf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_irf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mne_run_numbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazav_blank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne_theory_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0mne_exp_corrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mirf_blank_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mne_azav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazav_blank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_127834/2782190453.py\u001b[0m in \u001b[0;36mirf_blank_correction\u001b[0;34m(azav, azav_blank, irf)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'azav_blank:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mazav_blank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'irf:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mazav_corrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mazav\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mazav_blank\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mirf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mazav_corrected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m# END THOMAS FUNCTIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (35,) (33,) "
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# custom imports (from current directory)\n",
    "from run_numbers_vars import *  # contains dark, blank, Ne, SF6 run numbers\n",
    "\n",
    "###\n",
    "# FUNCTIONS\n",
    "def is_file(path):\n",
    "    return os.path.isfile(path)\n",
    "\n",
    "def runNumToString(num):\n",
    "    numstr = str(num)\n",
    "    while len(numstr)<4:\n",
    "        numstr = '0'+numstr\n",
    "    return numstr\n",
    "    \n",
    "def is_leaf(dataset):\n",
    "    return isinstance(dataset,h5py.Dataset)\n",
    "\n",
    "def get_leaves(f,saveto,verbose=False):\n",
    "    def return_leaf(name):\n",
    "        if is_leaf(f[name]):\n",
    "            if verbose:\n",
    "                print(name,f[name][()].shape)\n",
    "            saveto[name] = f[name][()]\n",
    "    f.visit(return_leaf)\n",
    "\n",
    "def combineRuns(runNumbers,folder,verbose=False):\n",
    "    data_array = []\n",
    "    for i,runNumber in enumerate(runNumbers):\n",
    "        data = {}\n",
    "        filename = f'{folder}cxilx9320_Run{runNumToString(runNumber)}.h5'\n",
    "        if is_file(filename):\n",
    "            print('%s, FILE EXISTS, CONTINUE...' % filename)\n",
    "        else:\n",
    "            print('%s, FILE DOES NOT EXIST!' % filename)\n",
    "        with h5py.File(filename,'r') as f:\n",
    "            get_leaves(f,data,verbose=verbose)\n",
    "            data_array.append(data)\n",
    "    hf1 = h5py.File(filename, 'r')\n",
    "#    for key in hf1['epicsAll']:\n",
    "#        print(key)\n",
    "    data_combined = {}\n",
    "    for key in keys_to_combine:\n",
    "        arr = np.squeeze(data_array[0][key])\n",
    "        for data in data_array[1:]:\n",
    "            arr = np.concatenate((arr,np.squeeze(data[key])),axis=0)\n",
    "        data_combined[key] = arr\n",
    "    run_indicator = np.array([])\n",
    "    for i,runNumber in enumerate(runNumbers):\n",
    "        run_indicator = np.concatenate((run_indicator,runNumber*np.ones_like(data_array[i]['tt/FLTPOS'])))\n",
    "    data_combined['run_indicator'] = run_indicator\n",
    "    for key in keys_to_sum:\n",
    "        arr = np.zeros_like(data_array[0][key])\n",
    "        for data in data_array:\n",
    "            arr += data[key]\n",
    "        data_combined[key] = arr\n",
    "    for key in keys_to_check:\n",
    "        arr = data_array[0][key]\n",
    "        for i,data in enumerate(data_array):\n",
    "            if not np.array_equal(data[key],arr):\n",
    "                print(f'Problem with key {key} in run {runNumbers[i]}')\n",
    "        data_combined[key] = arr\n",
    "    return data_combined\n",
    "# END FUNCTIONS\n",
    "###\n",
    "\n",
    "# KEYS\n",
    "keys_to_combine = ['tt/FLTPOS',\n",
    "                   'tt/AMPL',\n",
    "                   'tt/FLTPOSFWHM',\n",
    "                   'tt/ttCorr',\n",
    "                   'tt/FLTPOS_PS',\n",
    "                   'tt/AMPL',\n",
    "                   'tt/AMPLNXT',\n",
    "                   'tt/FLTPOS',\n",
    "                   'tt/FLTPOS_PS',\n",
    "                   'tt/REFAMPL',\n",
    "                   #'scan/lxt_ttc',\n",
    "                   'ipm_dg2/sum',\n",
    "                   'ipm_dg3/sum',\n",
    "                   'gas_detector/f_11_ENRC',\n",
    "                   #'epicsAll/gasCell_pressure',\n",
    "                   'jungfrau4M/azav_azav',\n",
    "                   'evr/code_183',\n",
    "                   'evr/code_162',\n",
    "                   'evr/code_141',\n",
    "                   #'epicsAll/gasCell_pressure',\n",
    "                   'lightStatus/laser',\n",
    "                   'lightStatus/xray',\n",
    "                   # 'scan/var0',\n",
    "                   #  'scan/LAS:FS5:MMS:PH',\n",
    "                  ]\n",
    "\n",
    "keys_to_sum = ['Sums/jungfrau4M_calib',\n",
    "              'Sums/jungfrau4M_calib_thresADU1']\n",
    "\n",
    "keys_to_check = ['UserDataCfg/jungfrau4M/azav__azav_q',\n",
    "                'UserDataCfg/jungfrau4M/azav__azav_qbin',\n",
    "                'UserDataCfg/jungfrau4M/azav__azav_qbins',\n",
    "                'UserDataCfg/jungfrau4M/x',\n",
    "                'UserDataCfg/jungfrau4M/y',\n",
    "                'UserDataCfg/jungfrau4M/z',\n",
    "                'UserDataCfg/jungfrau4M/azav__azav_matrix_q',\n",
    "                'UserDataCfg/jungfrau4M/azav__azav_matrix_phi',\n",
    "                'UserDataCfg/jungfrau4M/cmask',\n",
    "                #'UserDataCfg/jungfrau4M/Full_thres__Full_thres_thresADU',\n",
    "                #'UserDataCfg/jungfrau4M/Full_thres__Full_thres_bound',\n",
    "                'UserDataCfg/jungfrau4M/common_mode_pars']\n",
    "\n",
    "# END KEYS\n",
    "###\n",
    "\n",
    "# THOMAS FUNCTIONS\n",
    "def normalise(x, f):\n",
    "    f *= abs(x[1] - x[0])\n",
    "    f /= np.sum(f)\n",
    "    return f\n",
    "\n",
    "def get_azav(runNumbers):\n",
    "    '''\n",
    "    Returns normalised azimuthal average of Jungfrau for array of run numbers.\n",
    "    '''\n",
    "    data = combineRuns(runNumbers, folder=folder, verbose=False)\n",
    "    # azimuthal average\n",
    "    #azav = np.squeeze(data['jungfrau4M/azav_azav'])\n",
    "    azav  = data['jungfrau4M/azav_azav']\n",
    "    print('azav shape: '); print(azav.shape)\n",
    "    #print(azav.shape)\n",
    "    azav_sum = np.sum(azav, axis=0)\n",
    "    \n",
    "    # q definition\n",
    "    q = data['UserDataCfg/jungfrau4M/azav__azav_q']\n",
    "    #qbin  = data['UserDataCfg/jungfrau4M/azav__azav_qbin' ]\n",
    "    #qbins = data['UserDataCfg/jungfrau4M/azav__azav_qbins']\n",
    "    return q, azav_sum\n",
    "\n",
    "def load_theory(theory_file):\n",
    "    # Load theory file data\n",
    "    split_tup = os.path.splitext(theory_file)\n",
    "    filetype = split_tup[1]\n",
    "    if filetype == '.txt':\n",
    "        data = np.loadtxt(theory_file)\n",
    "    elif filetype == '.npy':\n",
    "        data = np.load(theory_file)\n",
    "        data = np.transpose(data)\n",
    "        print('npy data:'); print(data)\n",
    "        print(data.shape)\n",
    "    q_theory = data[0]\n",
    "    f_theory = data[1]\n",
    "    return q_theory, f_theory\n",
    "\n",
    "def interp_theory(q_exp, q_theory, f_theory):\n",
    "    # interpolate to shape of exp data\n",
    "    interpolated_values = np.interp(q_exp, q_theory, f_theory)  \n",
    "    return interpolated_values\n",
    "\n",
    "def get_irf(run_numbers, blank_subtraction, theory_file, q_exp, indexstart):\n",
    "    '''\n",
    "    Returns the instrument response function (IRF) for calibration run(s)\n",
    "    '''\n",
    "    # Get azav for run(s)\n",
    "    q_not_used, azav = get_azav(run_numbers)\n",
    "    # Subtract blank\n",
    "    azav_subtracted = azav - blank_subtraction\n",
    "    # interpolation (make theory curve same shape as experiment q-bins)\n",
    "    q_theory, f_theory = load_theory(theory_file)\n",
    "    q_exp = q_exp[indexstart:]\n",
    "    azav_subtracted = azav_subtracted[indexstart:]\n",
    "    theory_interp = interp_theory(q_exp, q_theory, f_theory)\n",
    "    #plt.plot(q_theory, ne_theory)\n",
    "    #plt.plot(q_exp, ne_theory_interp)\n",
    "    # Normalise before creating IRF\n",
    "    exp_normalised = normalise(q_exp, azav_subtracted)\n",
    "    theory_normalised = normalise(q_exp, theory_interp)\n",
    "    tmp = theory_normalised / exp_normalised\n",
    "    # convert nan and inf to 0\n",
    "    irf = np.nan_to_num(tmp, copy=True, posinf=0, neginf=0)\n",
    "    return irf\n",
    "\n",
    "def irf_blank_correction(azav, azav_blank, irf):\n",
    "    '''\n",
    "    Applies blank subtraction and IRF correction to an azav curve\n",
    "    '''\n",
    "    print('azav_blank:'); print(azav_blank)\n",
    "    print('irf:'); print(irf)\n",
    "    azav_corrected = (azav - azav_blank) * irf\n",
    "    return azav_corrected\n",
    "# END THOMAS FUNCTIONS\n",
    "###\n",
    "\n",
    "# BLANK RUN\n",
    "q, azav_blank = get_azav(blank_run_numbers)\n",
    "# END BLANK RUN\n",
    "###\n",
    "\n",
    "# Neon and IRF\n",
    "tmp, ne_azav = get_azav(ne_run_numbers)\n",
    "q_theory, ne_theory = load_theory(ne_theory_file)\n",
    "indexstart = 2\n",
    "irf = get_irf(ne_run_numbers, azav_blank, ne_theory_file, q, indexstart)\n",
    "ne_exp_corrected = irf_blank_correction(ne_azav, azav_blank, irf)\n",
    "plt.figure()\n",
    "plt.plot(q, normalise(q, irf))\n",
    "plt.plot(q, normalise(q, ne_azav))\n",
    "scale = np.max(normalise(q, ne_exp_corrected)) / np.max(normalise(q_theory, ne_theory))\n",
    "print('Ne theory scale = %f' % scale)\n",
    "plt.plot(q_theory, scale*normalise(q_theory, ne_theory)) \n",
    "plt.plot(q, normalise(q, ne_exp_corrected))\n",
    "plt.legend(['IRF', 'Ne experiment', 'Ne theory', 'Ne exp corrected'])\n",
    "\n",
    "# END Neon IRF\n",
    "###\n",
    "\n",
    "# SF6 sanity check\n",
    "q_theory, sf6_theory = load_theory(sf6_theory_file)\n",
    "sf6_theory_normalised = normalise(q_theory, sf6_theory)\n",
    "tmp, sf6_azav = get_azav(sf6_run_numbers)\n",
    "sf6_azav_corrected = irf_blank_correction(sf6_azav, azav_blank, irf)\n",
    "sf6_exp_normalised = normalise(q, sf6_azav_corrected)\n",
    "\n",
    "plt.figure()\n",
    "scale = np.max(sf6_exp_normalised) / np.max(sf6_theory_normalised)\n",
    "print('SF6 theory scale = %f' % scale)\n",
    "A = 3.1\n",
    "plt.plot(q_theory, A * scale * sf6_theory_normalised)\n",
    "#print('sf6 azav corrected:')\n",
    "#print(sf6_azav_corrected)\n",
    "start = 5\n",
    "plt.plot(q[start:], sf6_exp_normalised[start:], '.')\n",
    "plt.xlim([0, 7])\n",
    "plt.ylim([0, 0.1])\n",
    "plt.legend(['SF6 theory', 'SF6 exp corrected'])\n",
    "\n",
    "# END SF6 sanity check\n",
    "###\n",
    "\n",
    "print('Vector q ='); print(q)\n",
    "#print('Size of qbin increment: %f (A-1)' % qbin)\n",
    "#print('qbins:'); print(qbins)\n",
    "#print(x)\n",
    "#print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921510b-6e2b-4070-a267-0010a9b2fa08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec69a79-f495-4c6d-8e2d-396320f22728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCLS-I py3",
   "language": "python",
   "name": "ana1-current-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
